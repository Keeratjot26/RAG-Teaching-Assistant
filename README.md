# ğŸ“ RAGâ€‘Based Teaching Assistant

> Turn long lecture videos into a smart, searchable AI tutor.

This project implements a **Retrievalâ€‘Augmented Generation (RAG)** pipeline that converts lecture videos into audio, transcribes them, chunks the content, creates embeddings, and answers user queries using semantic search + LLM reasoning.

Think of it as: **your personal AI TA for any lecture, course, or talk**.

---

## âœ¨ What This Project Does (Highâ€‘Level Flow)

1. ğŸ¥ **Input**: Lecture videos (your own data)
2. ğŸ”Š **Audio Extraction**: Convert video â†’ audio using FFmpeg
3. ğŸ“ **Transcription**: Speechâ€‘toâ€‘text using Whisper
4. âœ‚ï¸ **Chunking**: Break long transcripts into meaningful chunks
5. ğŸ§  **Embeddings**: Convert chunks into vector embeddings
6. ğŸ” **Retrieval**: Match user query with relevant chunks using cosine similarity
7. ğŸ¤– **Generation**: Generate a contextual answer using a RAG approach

---

## ğŸ§± Project Architecture

```
Videos â†’ Audio â†’ Transcription â†’ Chunking â†’ Embeddings
                                      â†“
                              User Query Embedding
                                      â†“
                              Cosine Similarity Search
                                      â†“
                                RAG Answer Generation
```

---

## ğŸ› ï¸ Tech Stack

<p align="left">
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" />
  <img src="https://img.shields.io/badge/Whisper-000000?style=for-the-badge&logo=openai&logoColor=white" />
  <img src="https://img.shields.io/badge/FFmpeg-007808?style=for-the-badge&logo=ffmpeg&logoColor=white" />
  <img src="https://img.shields.io/badge/Vector%20Embeddings-6A5ACD?style=for-the-badge" />
  <img src="https://img.shields.io/badge/RAG-FF6F00?style=for-the-badge" />
</p>

---

## ğŸ“‚ Repository Structure

```
â”œâ”€â”€ video_to_mp3.py          # Converts video files to audio
â”œâ”€â”€ mp3_to_json.py           # Transcribes audio and creates JSON chunks
â”œâ”€â”€ preprocess_json.py       # Cleans and structures transcript data
â”œâ”€â”€ process_incoming.py      # Handles user queries + retrieval
â”œâ”€â”€ prompt.txt               # Prompt template for RAG
â”œâ”€â”€ response.txt             # Model responses
â”œâ”€â”€ .gitignore               # Excludes large media & generated files
â””â”€â”€ README.md
```

> âš ï¸ **Note**: Audio, video, embeddings, and generated JSON files are intentionally excluded due to GitHub size limits.

---

## ğŸš€ How to Use This RAG Teaching Assistant on Your Own Data

### 1ï¸âƒ£ Prerequisites

* Python 3.9+
* FFmpeg installed and added to PATH
* Whisper model available locally
* Required Python libraries installed

```bash
pip install -r requirements.txt
```

---

### 2ï¸âƒ£ Add Your Own Lecture Videos

Create the following folders locally (they are gitâ€‘ignored):

```bash
videos/
audios/
trimmed_audios/
jsons/
```

Place your lecture videos inside the `videos/` folder.

---

### 3ï¸âƒ£ Convert Videos to Audio

```bash
python video_to_mp3.py
```

This extracts audio from each video using FFmpeg.

---

### 4ï¸âƒ£ Transcribe & Chunk Audio

```bash
python mp3_to_json.py
```

This step:

* Converts speech â†’ text using Whisper
* Chunks transcripts for better retrieval

---

### 5ï¸âƒ£ Preprocess Transcript Data

```bash
python preprocess_json.py
```

Cleans and structures transcript chunks for embedding generation.

---

### 6ï¸âƒ£ Ask Questions (RAG in Action)

```bash
python process_incoming.py
```

Example queries:

* *"Explain Gramâ€‘Schmidt in simple terms"*
* *"What is the intuition behind projection matrices?"*
* *"Summarize todayâ€™s lecture in 5 points"*

The model retrieves the most relevant chunks and generates a grounded answer.

---

## ğŸ§  Why RAG Instead of Plain LLMs?

* âŒ No hallucinations from missing context
* âœ… Answers grounded in **your own lecture data**
* âœ… Scales to long videos & entire courses

---

## ğŸ“Œ Key Highlights

* Modular pipeline (easy to extend)
* Works on **any subject / any lecture**
* Localâ€‘first (no mandatory cloud dependency)
* Designed with real ML system constraints in mind

---

## ğŸ“ˆ Future Improvements

* Add a web UI (Streamlit / React)
* Persistent vector database (FAISS / Chroma)
* Multiâ€‘document crossâ€‘lecture reasoning
* Evaluation metrics for retrieval accuracy

---

## ğŸ™Œ Final Note

This project demonstrates an **endâ€‘toâ€‘end applied RAG system**, from raw videos to intelligent answers â€” built with realâ€‘world constraints and best practices.

If you found this useful, â­ the repo and feel free to fork & experiment.
